DEBUG:root:Creating folder `./models/2020-09-23_004245`
INFO:root:Saving configuration file in `/home/paperspace/learning-to-learn/models/2020-09-23_004245/config.json`
cuda
Namespace(batch_size=25, dataset='quickdraw', first_order=False, folder='/storage/smb79ck2/ndata/', hidden_size=20, meta_lr=0.001, num_batches=100, num_epochs=50, num_shots=5, num_shots_test=5, num_steps=5, num_training_samples=100, num_ways=10, num_workers=1, output_folder='./models', random_seed=123, step_size=0.01, use_cuda=True, verbose=True)
epoch           train loss      train acc       train prec      val loss        val acc         val prec     
1               1.97283         0.32575         0.31822         1.69638         0.45321         0.45612      
2               1.49963         0.52145         0.53143         1.44051         0.53807         0.54968      
3               1.29093         0.58535         0.60365         1.30018         0.58781         0.60185      
4               1.18346         0.62008         0.63849         1.24870         0.60346         0.61852      
5               1.09776         0.65070         0.67010         1.18570         0.62482         0.64220      
6               1.04106         0.66991         0.68980         1.13266         0.64475         0.66305      
7               0.99666         0.68388         0.70494         1.09537         0.65602         0.67377      
8               0.96618         0.69302         0.71246         1.09222         0.65708         0.67593      
9               0.94203         0.70331         0.72444         1.08697         0.65973         0.67758      
10              0.97210         0.69319         0.71361         1.13130         0.64349         0.66277      
11              0.94185         0.70034         0.72077         1.06927         0.66422         0.68254      
12              0.90681         0.71162         0.73203         1.10544         0.65385         0.67225      
13              0.89681         0.71664         0.73748         1.06477         0.66634         0.68383      
14              0.88594         0.71862         0.73899         1.05005         0.67086         0.68977      
15              0.85348         0.72882         0.74860         1.03753         0.67561         0.69378      
16              0.83900         0.73219         0.75253         1.02125         0.68006         0.69842      
17              0.85546         0.72762         0.74804         1.02231         0.67975         0.69702      
18              0.88970         0.71781         0.73993         1.09059         0.65702         0.67535      
19              0.85222         0.72879         0.74975         1.03357         0.67499         0.69340      
20              0.82390         0.73606         0.75666         1.04206         0.67519         0.69332      
21              0.81828         0.73935         0.75946         1.03102         0.67692         0.69402      
22              0.82729         0.73598         0.75632         1.03026         0.67652         0.69518      
23              0.81493         0.74029         0.76056         1.02104         0.68062         0.69915      
24              0.80424         0.74274         0.76298         1.02383         0.67890         0.69737      
25              0.79010         0.74704         0.76666         1.01882         0.68234         0.70142      
26              0.83546         0.73324         0.75373         1.04469         0.67254         0.69111      
27              0.84069         0.73183         0.75251         1.04490         0.67246         0.69196      
28              0.80630         0.74415         0.76468         1.03620         0.67650         0.69472      
29              0.81101         0.73976         0.75974         1.03646         0.67529         0.69339      
30              0.80122         0.74420         0.76318         1.03366         0.67632         0.69395      
31              0.79146         0.74794         0.76751         1.01649         0.68105         0.69818      
32              0.77188         0.75212         0.77151         1.01227         0.68379         0.70140      
33              0.78085         0.74998         0.77018         1.05390         0.66893         0.68683      
34              0.80553         0.74276         0.76285         1.02599         0.67986         0.69858      
35              0.77162         0.75390         0.77375         1.02161         0.68229         0.70121      
36              0.75931         0.75585         0.77496         1.02276         0.68218         0.69859      
37              0.76624         0.75386         0.77317         1.03584         0.67669         0.69334      
38              0.76845         0.75410         0.77429         1.02457         0.67940         0.69615      
39              0.75667         0.75565         0.77572         1.13145         0.64526         0.66538      
40              0.79653         0.74554         0.76628         1.02358         0.67857         0.69565      
41              0.76865         0.75551         0.77562         1.03407         0.67770         0.69487      
42              0.78176         0.74936         0.77012         1.01066         0.68474         0.70089      
43              0.74570         0.76056         0.77944         1.01879         0.67994         0.69609      
44              0.74710         0.76194         0.78118         1.03853         0.67402         0.69088      
45              0.74391         0.76042         0.78006         1.01421         0.68294         0.70049      
46              0.73429         0.76276         0.78202         1.01107         0.68648         0.70384      
47              0.72454         0.76598         0.78492         1.02472         0.67910         0.69592      
48              0.74477         0.75851         0.77822         1.05119         0.67329         0.69301      
49              0.82890         0.73700         0.75960         1.04717         0.67097         0.68957      
50              0.75401         0.75596         0.77483         1.02777         0.67779         0.69461      
